{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "999fff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FlowSequential(nn.Sequential):\n",
    "    def forward(self, inputs, inverse=False):\n",
    "        batch_size = inputs.size(0)\n",
    "        sum_LDJ = torch.zeros(batch_size, device=inputs.device)\n",
    "        if not inverse:\n",
    "            for m in self._modules.values():\n",
    "                inputs, LDJ = m(inputs, inverse=False)\n",
    "                sum_LDJ += LDJ\n",
    "            return inputs, sum_LDJ\n",
    "        else:\n",
    "            for m in reversed(self._modules.values()):\n",
    "                inputs, LDJ = m(inputs, inverse=True)\n",
    "                sum_LDJ += LDJ\n",
    "            return inputs, sum_LDJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56f7eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def check_tensors(tensor_dict, message):\n",
    "  for k, v in tensor_dict.items():\n",
    "    # inf check\n",
    "    if torch.isinf(v).any():\n",
    "      print(message)\n",
    "      print('--Found inf in %s' % k)\n",
    "      raise FloatingPointError\n",
    "    # nan check\n",
    "    if torch.isnan(v).any():\n",
    "      print(message)\n",
    "      print('--Found nan in %s' % k)\n",
    "      raise FloatingPointError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c3e0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AffineCouplingLayer(nn.Module):\n",
    "    def __init__(self, channels, channels_h):\n",
    "        super(AffineCouplingLayer, self).__init__()\n",
    "        self.channels = channels\n",
    "        d = channels // 2\n",
    "        conv1 = nn.Conv2d(d, channels_h, 3, 1, 1)\n",
    "        conv2 = nn.Conv2d(channels_h, channels_h, 1, 1, 0)\n",
    "        conv3 = nn.Conv2d(channels_h, (channels - d) * 2, 3, 1, 1)\n",
    "        def init_normal(m):\n",
    "            nn.init.normal_(m.weight.data, mean=0.0, std=0.05)\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "        def init_zero(m):\n",
    "            nn.init.constant_(m.weight.data, 0.0)\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "        conv1.apply(init_normal)\n",
    "        conv2.apply(init_normal)\n",
    "        conv3.apply(init_zero)\n",
    "        self.nn = nn.Sequential(conv1,\n",
    "                                nn.ReLU(True),\n",
    "                                conv2,\n",
    "                                nn.ReLU(True),\n",
    "                                conv3)\n",
    "        self.log_scale = nn.Parameter(torch.zeros(channels, 1, 1))\n",
    "\n",
    "    def split(self, x):\n",
    "        d = self.channels // 2\n",
    "        x1, x2 = torch.split(x, [d, self.channels - d], 1)\n",
    "        return x1, x2\n",
    "\n",
    "    def concat(self, x1, x2):\n",
    "        x = torch.cat([x1, x2], 1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, inputs, inverse=False):\n",
    "        batch_size = inputs.size(0)\n",
    "        if not inverse:\n",
    "            x1, x2 = self.split(inputs)\n",
    "            y1 = x1\n",
    "            log_s, t = torch.chunk(self.nn(x1) * self.log_scale.exp(), 2, 1)\n",
    "            #s = torch.exp(log_s)\n",
    "            s = torch.sigmoid(log_s + 2) + 1.0 # numerically stable ver\n",
    "            log_s = s.log()\n",
    "            y2 = x2 * s + t\n",
    "            y = self.concat(y1, y2)\n",
    "            LDJ = log_s.view(batch_size, -1).sum(-1)\n",
    "            check_tensors({'y': y, 'LDJ': LDJ}, str(self.__class__) + ': forward')\n",
    "            return y, LDJ\n",
    "        else:\n",
    "            y1, y2 = self.split(inputs)\n",
    "            x1 = y1\n",
    "            log_s, t = torch.chunk(self.nn(x1) * self.log_scale.exp(), 2, 1)\n",
    "            #s = torch.exp(log_s)\n",
    "            s = torch.sigmoid(log_s + 2) + 1.0 # numerically stable ver\n",
    "            log_s = s.log()\n",
    "            x2 = (y2 - t) / s\n",
    "            x = self.concat(x1, x2)\n",
    "            LDJ = -log_s.view(batch_size, -1).sum(-1)\n",
    "            check_tensors({'x': x, 'LDJ': LDJ}, str(self.__class__) + ': inverse')\n",
    "            return x, LDJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d6a10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InversibleConv1x1(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(InversibleConv1x1, self).__init__()\n",
    "        self.w = nn.Parameter(torch.qr(torch.randn(channels, channels))[0])\n",
    "\n",
    "    def forward(self, inputs, inverse=False):\n",
    "        batch_size = inputs.size(0)\n",
    "        pixels = inputs.size(-1) * inputs.size(-2)\n",
    "        if not inverse:\n",
    "            y = nn.functional.conv2d(inputs, self.w.unsqueeze(-1).unsqueeze(-1))\n",
    "            abs_det = torch.det(self.w).abs()\n",
    "            LDJ = abs_det.log().repeat(batch_size) * pixels\n",
    "            check_tensors({'y': y, 'LDJ': LDJ}, str(self.__class__) + ': forward')\n",
    "            return y, LDJ\n",
    "        else:\n",
    "            inv_w = torch.inverse(self.w)\n",
    "            x = nn.functional.conv2d(inputs, inv_w.unsqueeze(-1).unsqueeze(-1))\n",
    "            abs_det = torch.det(inv_w).abs()\n",
    "            LDJ = abs_det.log().repeat(batch_size) * pixels\n",
    "            check_tensors({'x': x, 'LDJ': LDJ}, str(self.__class__) + ': inverse')\n",
    "            return x, LDJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55b79c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ActNorm(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ActNorm, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.mean = nn.Parameter(torch.empty(channels, 1, 1))\n",
    "        self.log_std = nn.Parameter(torch.empty(channels, 1, 1))\n",
    "        self.initialized = False\n",
    "\n",
    "    def forward(self, inputs, inverse=False):\n",
    "        if not self.initialized:\n",
    "            inputs_view = inputs.transpose(0, 1).contiguous().view(self.channels, -1)\n",
    "            mean = inputs_view.mean(-1).view(-1, 1, 1)\n",
    "            std = inputs_view.std(-1).view(-1, 1, 1)\n",
    "            std = std.clamp(min=1e-16) # avoid nan\n",
    "            self.mean.data.copy_(mean)\n",
    "            self.log_std.data.copy_(std.log())\n",
    "            self.initialized = True\n",
    "\n",
    "        batch_size = inputs.size(0)\n",
    "        pixels = inputs.size(-1) * inputs.size(-2)\n",
    "        if not inverse:\n",
    "            y = (inputs - self.mean) * torch.exp(-self.log_std)\n",
    "            LDJ = -self.log_std.sum().repeat(batch_size) * pixels\n",
    "            check_tensors({'y': y, 'LDJ': LDJ}, str(self.__class__) + ': forward')\n",
    "            return y, LDJ\n",
    "        else:\n",
    "            x = inputs * torch.exp(self.log_std) + self.mean\n",
    "            LDJ = self.log_std.sum().repeat(batch_size) * pixels\n",
    "            check_tensors({'x': x, 'LDJ': LDJ}, str(self.__class__) + ': inverse')\n",
    "            return x, LDJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeaab630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Squeeze(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Squeeze, self).__init__()\n",
    "\n",
    "  def forward(self, inputs, inverse=False):\n",
    "    batch_size, c, h, w = inputs.size()\n",
    "    if not inverse:\n",
    "      x_view = inputs.contiguous().view(batch_size, c, h // 2, 2, w // 2, 2)\n",
    "      y = x_view.permute(0, 1, 3, 5, 2, 4).contiguous().view(batch_size, c * 4, h // 2, w // 2)\n",
    "      return y, torch.zeros(batch_size, device=inputs.device)\n",
    "    else:\n",
    "      y_view = inputs.contiguous().view(batch_size, c // 4, 2, 2, h, w)\n",
    "      x = y_view.permute(0, 1, 4, 2, 5, 3).contiguous().view(batch_size, c // 4, h * 2, w * 2)\n",
    "      return x, torch.zeros(batch_size, device=inputs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "947b3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Glow(nn.Module):\n",
    "    def __init__(self, input_size, channels_h, K, L, save_memory=False):\n",
    "        super(Glow, self).__init__()\n",
    "        self.L = L\n",
    "        self.save_memory = save_memory\n",
    "        self.output_sizes = []\n",
    "        blocks = []\n",
    "        c, h, w = input_size\n",
    "        for l in range(L):\n",
    "            block = [Squeeze()]\n",
    "            c *= 4; h //= 2; w //= 2 # squeeze\n",
    "            for _ in range(K):\n",
    "                norm_layer = ActNorm(c)\n",
    "                if save_memory:\n",
    "                    perm_layer = flows.RandomRotation(c) # easily inversible ver\n",
    "                else:\n",
    "                    perm_layer = InversibleConv1x1(c)\n",
    "                coupling_layer = AffineCouplingLayer(c, channels_h)\n",
    "                block += [norm_layer, perm_layer, coupling_layer]\n",
    "            blocks.append(FlowSequential(*block))\n",
    "            self.output_sizes.append((c, h, w))\n",
    "            c //= 2 # split\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, inputs, inverse=False):\n",
    "        batch_size = inputs.size(0)\n",
    "        if not inverse:\n",
    "            h = inputs\n",
    "            sum_LDJ = 0\n",
    "            xs = []\n",
    "            for l in range(self.L):\n",
    "                if self.save_memory:\n",
    "                    h, LDJ = flows.rev_sequential(self.blocks[l], h, inverse=False)\n",
    "                else:\n",
    "                    h, LDJ = self.blocks[l](h, inverse=False)\n",
    "                sum_LDJ += LDJ\n",
    "                if l < self.L - 1:\n",
    "                    x, h = torch.chunk(h, 2, 1)\n",
    "                else:\n",
    "                    x = h\n",
    "                xs.append(x.view(batch_size, -1))\n",
    "            x = torch.cat(xs, -1)\n",
    "            return x, sum_LDJ\n",
    "        else:\n",
    "            sections = [inputs.size(-1) // (2 ** (l + 1)) for l in range(self.L)]\n",
    "            sections[-1] *= 2\n",
    "            xs = torch.split(inputs, sections, -1)\n",
    "            h = xs[-1]\n",
    "            sum_LDJ = 0\n",
    "            for l in reversed(range(self.L)):\n",
    "                h = h.view(batch_size, *self.output_sizes[l])\n",
    "                if self.save_memory:\n",
    "                    h, LDJ = flows.rev_sequential(self.blocks[l], h, inverse=True)\n",
    "                else:\n",
    "                    h, LDJ = self.blocks[l](h, inverse=True)\n",
    "                sum_LDJ += LDJ\n",
    "                if l > 0:\n",
    "                    h = torch.cat([xs[l - 1], h.view(batch_size, -1)], -1)\n",
    "            y = h\n",
    "            return y, sum_LDJ\n",
    "    \n",
    "    def log_prob(self, y):\n",
    "        x, LDJ = self.forward(y, inverse=False)\n",
    "        log_2pi = 0.79817986835\n",
    "        log_p_x = -0.5 * (x.pow(2) + log_2pi).sum(-1) # x ~ N(0, I)\n",
    "        log_p_y = log_p_x + LDJ\n",
    "        return log_p_y\n",
    "\n",
    "    def sample(self, n, device, temperature=1.0):\n",
    "        size = self.output_sizes[0][0] * self.output_sizes[0][1] * self.output_sizes[0][2]\n",
    "        x = torch.randn(n, size, device=device) * temperature # sample from the reduced-temperature distribution\n",
    "        y, LDJ = self.forward(x, inverse=True)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b5165be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Args\n",
      "{'datasets_dir': './pixelcnn-pp', 'out_dir': './out', 'channels_h': 512, 'K': 32, 'L': 3, 'lr': 0.001, 'weight_decay': 1e-06, 'batch_size': 512, 'epochs': 2, 'save_memory': False, 'display_interval': 1, 'sample_interval': 1, 'temperature': 0.7, 'save_model_interval': 5}\n",
      "==> Device\n",
      "cpu\n",
      "==> Dataset\n",
      "Files already downloaded and verified\n",
      "size of train data: 50000\n",
      "size of test data: 10000\n",
      "image size: torch.Size([3, 32, 32])\n",
      "==> Model\n",
      "==> Start learning\n",
      "[     1][     1] | loss: -6205.0664\n",
      "[     1][     2] | loss: -5096.6089\n",
      "[     1][     3] | loss: -5509.6079\n",
      "[     1][     4] | loss: -5614.7944\n",
      "[     1][     5] | loss: -5903.1797\n",
      "[     1][     6] | loss: -6336.6875\n",
      "[     1][     7] | loss: -6334.7925\n",
      "[     1][     8] | loss: -6363.0947\n",
      "[     1][     9] | loss: -6426.0122\n",
      "[     1][    10] | loss: -6392.5610\n",
      "[     1][    11] | loss: -6455.3369\n",
      "[     1][    12] | loss: -6489.9492\n",
      "[     1][    13] | loss: -6470.3179\n",
      "[     1][    14] | loss: -6545.1572\n",
      "[     1][    15] | loss: -6608.5215\n",
      "[     1][    16] | loss: -6696.6191\n",
      "[     1][    17] | loss: -6695.9492\n",
      "[     1][    18] | loss: -6763.7329\n",
      "[     1][    19] | loss: -6786.5527\n",
      "[     1][    20] | loss: -6811.9199\n",
      "[     1][    21] | loss: -6833.3550\n",
      "[     1][    22] | loss: -6868.4727\n",
      "[     1][    23] | loss: -6924.4556\n",
      "[     1][    24] | loss: -7023.7905\n",
      "[     1][    25] | loss: -6977.5674\n",
      "[     1][    26] | loss: -7108.1821\n",
      "[     1][    27] | loss: -7072.9341\n",
      "[     1][    28] | loss: -7070.8447\n",
      "[     1][    29] | loss: -7172.4009\n",
      "[     1][    30] | loss: -7206.6729\n",
      "[     1][    31] | loss: -7287.5679\n",
      "[     1][    32] | loss: -7191.3633\n",
      "[     1][    33] | loss: -7283.6235\n",
      "[     1][    34] | loss: -7334.5234\n",
      "[     1][    35] | loss: -7398.2480\n",
      "[     1][    36] | loss: -7481.1768\n",
      "[     1][    37] | loss: -7469.2339\n",
      "[     1][    38] | loss: -7537.7007\n",
      "[     1][    39] | loss: -7583.0371\n",
      "[     1][    40] | loss: -7653.2695\n",
      "[     1][    41] | loss: -7673.0454\n",
      "[     1][    42] | loss: -7684.0801\n",
      "[     1][    43] | loss: -7757.9639\n",
      "[     1][    44] | loss: -7796.0078\n",
      "[     1][    45] | loss: -7839.3232\n",
      "[     1][    46] | loss: -7850.9971\n",
      "[     1][    47] | loss: -7884.1118\n",
      "[     1][    48] | loss: -7938.9878\n",
      "[     1][    49] | loss: -7864.8296\n",
      "[     1][    50] | loss: -7500.8862\n",
      "[     1][    51] | loss: -7829.9009\n",
      "[     1][    52] | loss: -7926.0112\n",
      "[     1][    53] | loss: -7989.0972\n",
      "[     1][    54] | loss: -8018.8320\n",
      "[     1][    55] | loss: -8141.1885\n",
      "[     1][    56] | loss: -8107.6089\n",
      "[     1][    57] | loss: -8220.8369\n",
      "[     1][    58] | loss: -8195.7324\n",
      "[     1][    59] | loss: -8220.2422\n",
      "[     1][    60] | loss: -8336.3057\n",
      "[     1][    61] | loss: -8278.1357\n",
      "[     1][    62] | loss: -8282.3906\n",
      "[     1][    63] | loss: -8438.9805\n",
      "[     1][    64] | loss: -8345.8096\n",
      "[     1][    65] | loss: -8417.9893\n",
      "[     1][    66] | loss: -8475.2822\n",
      "[     1][    67] | loss: -8544.8633\n",
      "[     1][    68] | loss: -8508.3721\n",
      "[     1][    69] | loss: -8560.2588\n",
      "[     1][    70] | loss: -8565.6055\n",
      "[     1][    71] | loss: -8577.0879\n",
      "[     1][    72] | loss: -8594.3672\n",
      "[     1][    73] | loss: -8666.3984\n",
      "[     1][    74] | loss: -8662.2520\n",
      "[     1][    75] | loss: -8744.9844\n",
      "[     1][    76] | loss: -8750.1689\n",
      "[     1][    77] | loss: -8771.1035\n",
      "[     1][    78] | loss: -8793.0625\n",
      "[     1][    79] | loss: -8774.6719\n",
      "[     1][    80] | loss: -8788.4121\n",
      "[     1][    81] | loss: -8619.5732\n",
      "[     1][    82] | loss: -8574.2021\n",
      "[     1][    83] | loss: -8799.8525\n",
      "[     1][    84] | loss: -8818.6650\n",
      "[     1][    85] | loss: -8781.8662\n",
      "[     1][    86] | loss: -8831.3633\n",
      "[     1][    87] | loss: -8838.0947\n",
      "[     1][    88] | loss: -8772.7998\n",
      "[     1][    89] | loss: -8827.5312\n",
      "[     1][    90] | loss: -8884.0527\n",
      "[     1][    91] | loss: -8974.1895\n",
      "[     1][    92] | loss: -8911.3779\n",
      "[     1][    93] | loss: -8927.3535\n",
      "[     1][    94] | loss: -8909.4961\n",
      "[     1][    95] | loss: -8942.8203\n",
      "[     1][    96] | loss: -8994.0723\n",
      "[     1][    97] | loss: -9128.3154\n",
      "[     1][    98] | loss: -9155.1699\n",
      "==> Epoch1 Average Loss | loss: -7760.3305\n",
      "==> Epoch1 Test Loss | loss: -9034.2750\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './out\\\\dump.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 128>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    133\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train(epoch)\n\u001b[0;32m    134\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m test(epoch)\n\u001b[1;32m--> 135\u001b[0m \u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39msave_model_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    137\u001b[0m     params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(train_loss, test_loss)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(train_loss, test_loss):\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdump.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    126\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (train_loss, test_loss))\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './out\\\\dump.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join, exists\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Parse args\n",
    "print('==> Args')\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--datasets_dir', default='./Glow-CIAR10', type=str,\n",
    "                    help='Directory of datasets')\n",
    "parser.add_argument('--out_dir', default='./out_Glow', type=str,\n",
    "                    help='Directory to put the training result')\n",
    "parser.add_argument('--channels_h', default=512, type=int,\n",
    "                    help='Number of channels of hidden layers of conv-nets')\n",
    "parser.add_argument('--K', default=32, type=int,\n",
    "                    help='Depth of flow')\n",
    "parser.add_argument('--L', default=3, type=int,\n",
    "                    help='Number of levels')\n",
    "parser.add_argument('--lr', default=1e-3, type=float,\n",
    "                    help='Learning rate')\n",
    "parser.add_argument('--weight_decay', default=1e-6, type=float,\n",
    "                    help='Weight decay')\n",
    "parser.add_argument('--batch_size', default=512, type=int,\n",
    "                    help='Mini-batch size')\n",
    "parser.add_argument('--epochs', default=2, type=int,\n",
    "                    help='Number of epochs to train totally')\n",
    "parser.add_argument('--save_memory', action='store_true',\n",
    "                    help='Enables memory-saving backpropagation')\n",
    "parser.add_argument('--display_interval', default=1, type=int,\n",
    "                    help='Steps between logging training details')\n",
    "parser.add_argument('--sample_interval', default=1, type=int,\n",
    "                    help='Epochs between sampling')\n",
    "parser.add_argument('--temperature', default=0.7, type=float,\n",
    "                    help='Temperature of distribution to sample from')\n",
    "parser.add_argument('--save_model_interval', default=5, type=int,\n",
    "                    help='Epochs between saving model')\n",
    "args = parser.parse_args(args=[])\n",
    "print(vars(args))\n",
    "\n",
    "# Device\n",
    "print('==> Device')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "# Dataset\n",
    "print('==> Dataset')\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.CIFAR10(args.datasets_dir, train=True,\n",
    "                                 transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR10(args.datasets_dir, train=False,\n",
    "                                transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=args.batch_size,\n",
    "                                          shuffle=True)\n",
    "image_size = train_dataset[0][0].size()\n",
    "print('size of train data: %d' % len(train_dataset))\n",
    "print('size of test data: %d' % len(test_dataset))\n",
    "print('image size: %s' % str(image_size))\n",
    "\n",
    "# Model\n",
    "print('==> Model')\n",
    "model = Glow(image_size, args.channels_h, args.K, args.L,\n",
    "             save_memory=args.save_memory).to(device)\n",
    "#print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "def train(epoch):\n",
    "    # warmup\n",
    "    lr = min(args.lr * epoch / 10, args.lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    count = 0\n",
    "    for iteration, batch in enumerate(train_loader, 1):\n",
    "        batch = batch[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = -model.log_prob(batch)\n",
    "        mean_loss = loss.mean()\n",
    "        mean_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += loss.sum().item()\n",
    "        if iteration % args.display_interval == 0:\n",
    "            print('[%6d][%6d] | loss: %.4f' % \\\n",
    "                  (epoch, iteration, mean_loss.item()))\n",
    "    average_loss = sum_loss / len(train_dataset)\n",
    "    print('==> Epoch%d Average Loss | loss: %.4f' % \\\n",
    "          (epoch, average_loss))\n",
    "    return average_loss\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    sum_loss = 0\n",
    "    for iteration, batch in enumerate(test_loader, 1):\n",
    "        batch = batch[0].to(device)\n",
    "        with torch.no_grad():\n",
    "            loss = -model.log_prob(batch)\n",
    "        sum_loss += loss.sum().item()\n",
    "\n",
    "    average_loss = sum_loss / len(test_dataset)\n",
    "    print('==> Epoch%d Test Loss | loss: %.4f' % \\\n",
    "          (epoch, average_loss))\n",
    "    if epoch % args.sample_interval == 0:\n",
    "        n_samples = 64\n",
    "        with torch.no_grad():\n",
    "            sample = model.sample(n_samples, device).detach().cpu()\n",
    "        save_image(sample, join(args.out_dir, 'sample_%06d.png' % epoch), nrow=8)\n",
    "    return average_loss\n",
    "\n",
    "def dump(train_loss, test_loss):\n",
    "    with open(join(args.out_dir, 'dump.csv'), mode='a') as f:\n",
    "        f.write('%.4f, %.4f\\n' % (train_loss, test_loss))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if not exists(args.out_dir):\n",
    "        os.mkdir(args.out_dir)\n",
    "    print('==> Start learning')\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train_loss = train(epoch)\n",
    "        test_loss = test(epoch)\n",
    "        dump(train_loss, test_loss)\n",
    "        if epoch % args.save_model_interval == 0:\n",
    "            params = model.state_dict()\n",
    "            torch.save(params, join(args.out_dir, 'model_%06d' % epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39885ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde4432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
